{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Window Retriever ###\n",
    "- Embed each sentence for retrieval\n",
    "- Send a \"window\" of surrounding sentences for generation\n",
    "- Supported Strategies\n",
    "    - S002_00 -> Sentence Window\n",
    "    - S001_01 -> Sentence Window  + Rereank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch API keys from config.py\n",
    "import os\n",
    "from config import set_environment \n",
    "set_environment()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "#logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "#logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# Only for notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from llama_index.llms.cohere import Cohere\n",
    "from llama_index.embeddings.cohere import CohereEmbedding\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the model for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_llm_family = os.environ[\"GENERATION_LLM_FAMILY\"]\n",
    "generation_llm_model = os.environ[\"GENERATION_LLM_MODEL\"]\n",
    "\n",
    "if generation_llm_family == \"OPENAI\":\n",
    "    Settings.llm = OpenAI(temperature=0, model=generation_llm_model)\n",
    "elif generation_llm_family == \"COHERE\":\n",
    "    Settings.llm = Cohere(api_key=os.environ[\"COHERE_API_KEY\"], model=generation_llm_model,temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the model for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_llm_family = os.environ[\"EMBEDDING_LLM_FAMILY\"]\n",
    "embedding_llm_model = os.environ[\"EMBEDDING_LLM_MODEL\"]\n",
    "embedding_dimensions = int(os.environ[\"EMBEDDING_DIMESIONS\"])\n",
    "\n",
    "if embedding_llm_family == \"OPENAI\":\n",
    "    Settings.embed_model = OpenAIEmbedding(model=embedding_llm_model,dimensions=embedding_dimensions,)\n",
    "elif embedding_llm_family == \"COHERE\":\n",
    "    Settings.embed_model = CohereEmbedding(\n",
    "    cohere_api_key=os.environ[\"COHERE_API_KEY\"],\n",
    "    model_name=embedding_llm_model,\n",
    "    input_type=\"search_query\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for the run here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_name = os.environ[\"EVAL_NAME\"]\n",
    "eval_directory = os.environ[\"EVAL_DIRECTORY\"]\n",
    "eval_file = os.environ[\"EVAL_FILE\"]\n",
    "eval_questions = os.environ[\"EVAL_QUESTIONS\"]\n",
    "eval_results_dir = os.environ[\"EVAL_RESULTS_DIR\"]\n",
    "eval_quick_test = os.environ[\"EVAL_QUICK_TEST\"]\n",
    "\n",
    "rag_strategy = os.environ[\"RAG_STRATEGY\"]\n",
    "\n",
    "similarity_top_k = int(os.environ[\"SIMILARITY_TOP_K\"])\n",
    "\n",
    "# Context Post Processor Settings\n",
    "similarity_cutoff = float(os.environ[\"SIMILARITY_CUTOFF\"])\n",
    "\n",
    "# Node Parser\n",
    "window_size = int(os.environ[\"WINDOW_SIZE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rag_strategy == \"S002_00\":\n",
    "    rag_strategy_desc = \"SWindow_Basic\"\n",
    "    run_id = f\"{eval_name}_{rag_strategy}_GM_{generation_llm_model}_EM_{embedding_llm_model}_W_{window_size}_K_{similarity_top_k}_{datetime.today().strftime('%Y-%m-%d')}\"\n",
    "elif rag_strategy == \"S002_01\": \n",
    "    rag_strategy_desc = \"SWindow_Rerank\"\n",
    "    reranker = os.environ[\"RERANKER\"]\n",
    "    rerank_top_n = int(os.environ[\"RERANK_TOP_N\"])\n",
    "    run_id = f\"{eval_name}_{rag_strategy}_GM_{generation_llm_model}_EM_{embedding_llm_model}_W_{window_size}_K_{similarity_top_k}_RR_{reranker}_N_{rerank_top_n}_{datetime.today().strftime('%Y-%m-%d')}\"\n",
    "\n",
    "output_file = f\"{eval_results_dir}/{run_id}.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Token Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from llama_index.core.callbacks import CallbackManager, TokenCountingHandler\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-4\").encode\n",
    ")\n",
    "\n",
    "Settings.callback_manager = CallbackManager([token_counter])\n",
    "tokencount_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the documents, create chunks, calculate embeddings, store in a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a70cd4bdc04e8998a5f2ab379ad93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f191feb0a134968bd638f2e6b69801f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=window_size,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "# base node parser is a sentence splitter\n",
    "text_splitter = SentenceSplitter()\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "documents = SimpleDirectoryReader(eval_directory).load_data()\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "sentence_index = VectorStoreIndex(nodes,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokencount_df['document_tokens'] = [token_counter.total_embedding_token_count]\n",
    "token_counter.reset_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up retrieval and response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rag_strategy ==\"S002_00\":\n",
    "    node_postprocessors = [\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ]\n",
    "elif rag_strategy == \"S002_01\":\n",
    "    cohere_rerank = CohereRerank(api_key=os.environ[\"COHERE_API_KEY\"], top_n=rerank_top_n)\n",
    "    node_postprocessors = [\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\"), cohere_rerank\n",
    "    ]\n",
    "\n",
    "query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k= similarity_top_k,\n",
    "    # the target key defaults to `window` to match the node_parser's default\n",
    "    node_postprocessors=node_postprocessors,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test of query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:Are bifocals covered?\n",
      "\n",
      "Response:\n",
      "Yes, bifocals are covered under the Vision Service Plan (VSP). The plan pays in full for any necessary spectacle lenses, including bifocals.\n",
      "\n",
      "**Node ID:** 00d02a0a-338b-4f0c-8e53-2c0bb4b66421\n",
      "**Similarity:** 0.87439936\n",
      "**Text:**  \n",
      "2024 ACME  America, Inc.  Flexible Benefit Plan Document and SPD                                                                                                                                                                    133  \n",
      "    \n",
      "  \n",
      "• Two Pairs of Lenses In Lieu Of Bifocals  \n",
      "• Contact Lenses Solution and Miscellaneous Supplies  \n",
      "• Low Level Prescription Lenses (i.e., any prescription under 0.5 diopters)  \n",
      "  \n",
      "APPEALING A DENIED VSP CLAIM  \n",
      "  \n",
      "Initial Determination    \n",
      "VSP will pay or deny claims within 30 calendar days of the receipt of the claim from the individual or their authorized \n",
      "representative.  In the event that a claim cannot be resolved within the time indicated VSP may, if necessary, extend \n",
      "the time for decisi on by no more than 15 calendar days.  If VSP needs such an extension, VSP will notify You prior to \n",
      "the expiration of the initial 30 -day period, state the reason why the extension is needed, and state when it will make \n",
      "its determination.  If an extension is n eeded because You did not provide sufficient information or filed an incomplete \n",
      "claim, the time from the date of VSP’s notice requesting further information and an extension until VSP receives the \n",
      "requested information will not count toward the time period  VSP is allowed to notify You as to its claim decision.  You \n",
      "will have 45 days to provide the requested information from the date You receive the notice requesting further \n",
      "information from VSP.  When the claim has been processed, You will be notified of the benefits paid. \n",
      "\n",
      "------------------\n",
      "***Original Sentence***:\n",
      " Flexible Benefit Plan Document and SPD                                                                                                                                                                    133  \n",
      "    \n",
      "  \n",
      "• Two Pairs of Lenses In Lieu Of Bifocals  \n",
      "• Contact Lenses Solution and Miscellaneous Supplies  \n",
      "• Low Level Prescription Lenses (i.e., any prescription under 0.5 diopters)  \n",
      "  \n",
      "APPEALING A DENIED VSP CLAIM  \n",
      "  \n",
      "Initial Determination    \n",
      "VSP will pay or deny claims within 30 calendar days of the receipt of the claim from the individual or their authorized \n",
      "representative. \n",
      "------------------\n",
      "***Window***:\n",
      " \n",
      "2024 ACME  America, Inc.  Flexible Benefit Plan Document and SPD                                                                                                                                                                    133  \n",
      "    \n",
      "  \n",
      "• Two Pairs of Lenses In Lieu Of Bifocals  \n",
      "• Contact Lenses Solution and Miscellaneous Supplies  \n",
      "• Low Level Prescription Lenses (i.e., any prescription under 0.5 diopters)  \n",
      "  \n",
      "APPEALING A DENIED VSP CLAIM  \n",
      "  \n",
      "Initial Determination    \n",
      "VSP will pay or deny claims within 30 calendar days of the receipt of the claim from the individual or their authorized \n",
      "representative.  In the event that a claim cannot be resolved within the time indicated VSP may, if necessary, extend \n",
      "the time for decisi on by no more than 15 calendar days.  If VSP needs such an extension, VSP will notify You prior to \n",
      "the expiration of the initial 30 -day period, state the reason why the extension is needed, and state when it will make \n",
      "its determination.  If an extension is n eeded because You did not provide sufficient information or filed an incomplete \n",
      "claim, the time from the date of VSP’s notice requesting further information and an extension until VSP receives the \n",
      "requested information will not count toward the time period  VSP is allowed to notify You as to its claim decision.  You \n",
      "will have 45 days to provide the requested information from the date You receive the notice requesting further \n",
      "information from VSP.  When the claim has been processed, You will be notified of the benefits paid. \n",
      "~~~~\n",
      "**Node ID:** 20fbb697-451c-41a8-b4b1-efc235ecd168\n",
      "**Similarity:** 0.8085212\n",
      "**Text:** Note: If You use a VSP doctor but do not have the doctor verify eligibility prior to receiving services, any \n",
      "benefits will be paid at the Non -Network benefit level.  \n",
      "  \n",
      " VISION - CLAIM PROCEDURES  \n",
      "If You receive services from a non -VSP provider, You must follow these steps:  \n",
      "• Pay the provider the full amount of the bill and request a copy of the bill that shows the amount of the eye \n",
      "exam, lens type, and frame  \n",
      "• Visit the Benefits section of www.vsp.com  to begin Your claim.  \n",
      " • Complete the claim form.  Make sure You have a copy of Your itemized receipt or statement that includes: o \n",
      " Doctor name or office name o  Name of Patient o  Date of Service o  Each service \n",
      "received and the amount paid  \n",
      "• After completing the claim form, You may attach Your receipt(s) or print and mail copies of Your claim form \n",
      "and receipt(s) to:  Vision Service Plan (VSP)   \n",
      "PO Box 495918  \n",
      "Cincinnati, OH 45249 -5918  \n",
      "  \n",
      "VISION - PLAN EXCLUSIONS (WHAT IS NOT COVERED)  \n",
      "VSP pays in full any necessary spectacle lenses, including single vision, bifocal, trifocal or other more complex and \n",
      "expensive lenses necessary for Your visual welfare.  You may elect lenses or lens characteristics that are not \n",
      "necessary for Your visual we lfare, but You will pay for those cosmetic options.  For example, You would be \n",
      "responsible for the costs for the following elective services and supplies:  \n",
      "• Blended or Progressive Multifocal Lenses (except standard progressive lenses)  \n",
      "• Cosmetic Lenses  \n",
      "• Frames In Excess of The Plan Allowance  \n",
      "• Optional Cosmetic Processes  \n",
      "• Oversize, Coated Or Laminated Lenses  \n",
      "• Certain Limitations On Low Vision Care  \n",
      "• Any Supplemental Tests or Fittings Associated With Contact Lenses  \n",
      "• Exam or Eye -Wear Required By An Employer As a Condition of Employment  \n",
      "• Medical or Surgical Treatment  \n",
      "• Non-Prescription Lenses (except following LASIK/PRK surgery)  \n",
      "• Vision Training  \n",
      "• Services During Periods of Ineligibility (e.g., services received outside the normal interval)  \n",
      "\n",
      "------------------\n",
      "***Original Sentence***:\n",
      " For example, You would be \n",
      "responsible for the costs for the following elective services and supplies:  \n",
      "• Blended or Progressive Multifocal Lenses (except standard progressive lenses)  \n",
      "• Cosmetic Lenses  \n",
      "• Frames In Excess of The Plan Allowance  \n",
      "• Optional Cosmetic Processes  \n",
      "• Oversize, Coated Or Laminated Lenses  \n",
      "• Certain Limitations On Low Vision Care  \n",
      "• Any Supplemental Tests or Fittings Associated With Contact Lenses  \n",
      "• Exam or Eye -Wear Required By An Employer As a Condition of Employment  \n",
      "• Medical or Surgical Treatment  \n",
      "• Non-Prescription Lenses (except following LASIK/PRK surgery)  \n",
      "• Vision Training  \n",
      "• Services During Periods of Ineligibility (e.g., services received outside the normal interval)  \n",
      "------------------\n",
      "***Window***:\n",
      "Note: If You use a VSP doctor but do not have the doctor verify eligibility prior to receiving services, any \n",
      "benefits will be paid at the Non -Network benefit level.  \n",
      "  \n",
      " VISION - CLAIM PROCEDURES  \n",
      "If You receive services from a non -VSP provider, You must follow these steps:  \n",
      "• Pay the provider the full amount of the bill and request a copy of the bill that shows the amount of the eye \n",
      "exam, lens type, and frame  \n",
      "• Visit the Benefits section of www.vsp.com  to begin Your claim.  \n",
      " • Complete the claim form.  Make sure You have a copy of Your itemized receipt or statement that includes: o \n",
      " Doctor name or office name o  Name of Patient o  Date of Service o  Each service \n",
      "received and the amount paid  \n",
      "• After completing the claim form, You may attach Your receipt(s) or print and mail copies of Your claim form \n",
      "and receipt(s) to:  Vision Service Plan (VSP)   \n",
      "PO Box 495918  \n",
      "Cincinnati, OH 45249 -5918  \n",
      "  \n",
      "VISION - PLAN EXCLUSIONS (WHAT IS NOT COVERED)  \n",
      "VSP pays in full any necessary spectacle lenses, including single vision, bifocal, trifocal or other more complex and \n",
      "expensive lenses necessary for Your visual welfare.  You may elect lenses or lens characteristics that are not \n",
      "necessary for Your visual we lfare, but You will pay for those cosmetic options.  For example, You would be \n",
      "responsible for the costs for the following elective services and supplies:  \n",
      "• Blended or Progressive Multifocal Lenses (except standard progressive lenses)  \n",
      "• Cosmetic Lenses  \n",
      "• Frames In Excess of The Plan Allowance  \n",
      "• Optional Cosmetic Processes  \n",
      "• Oversize, Coated Or Laminated Lenses  \n",
      "• Certain Limitations On Low Vision Care  \n",
      "• Any Supplemental Tests or Fittings Associated With Contact Lenses  \n",
      "• Exam or Eye -Wear Required By An Employer As a Condition of Employment  \n",
      "• Medical or Surgical Treatment  \n",
      "• Non-Prescription Lenses (except following LASIK/PRK surgery)  \n",
      "• Vision Training  \n",
      "• Services During Periods of Ineligibility (e.g., services received outside the normal interval)  \n",
      "~~~~\n",
      "**Node ID:** 3cb4b238-d52a-4401-a168-bab4f59d3999\n",
      "**Similarity:** 0.47412896\n",
      "**Text:** MetLife \n",
      "can also make or recover payments.  \n",
      " VISION PLANS    \n",
      "This section of the Plan Document and Summary Plan Description outlines the key features and provisions of the \n",
      "Vision Service Plan (VSP) Plans.  For additional information about Plan coverage, refer to the Vision Plan \n",
      "Comparison Chart , which is incorporated herein by reference and is a part of this Plan document and Summary Plan \n",
      "Description.  \n",
      "  \n",
      " VISION - PLAN CHOICES  \n",
      "The Plan offers You a choice of the following two vision Plans:  \n",
      "❖ Vision Plan I — Allows You to obtain glasses (frame & lenses) or contacts once every Calendar Year.  \n",
      " ❖ Vision Plan II — Allows You to obtain glasses (frame & lenses) or contacts twice every Calendar Year.  This \n",
      "Plan also provides a higher level of coverage for frames or elective contact lenses.  \n",
      "  \n",
      "\n",
      "------------------\n",
      "***Original Sentence***:\n",
      " This \n",
      "Plan also provides a higher level of coverage for frames or elective contact lenses.  \n",
      "  \n",
      "------------------\n",
      "***Window***:\n",
      "MetLife \n",
      "can also make or recover payments.  \n",
      " VISION PLANS    \n",
      "This section of the Plan Document and Summary Plan Description outlines the key features and provisions of the \n",
      "Vision Service Plan (VSP) Plans.  For additional information about Plan coverage, refer to the Vision Plan \n",
      "Comparison Chart , which is incorporated herein by reference and is a part of this Plan document and Summary Plan \n",
      "Description.  \n",
      "  \n",
      " VISION - PLAN CHOICES  \n",
      "The Plan offers You a choice of the following two vision Plans:  \n",
      "❖ Vision Plan I — Allows You to obtain glasses (frame & lenses) or contacts once every Calendar Year.  \n",
      " ❖ Vision Plan II — Allows You to obtain glasses (frame & lenses) or contacts twice every Calendar Year.  This \n",
      "Plan also provides a higher level of coverage for frames or elective contact lenses.  \n",
      "  \n",
      "~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(eval_quick_test)\n",
    "print(f\"Question:{eval_quick_test}{chr(10)}\")\n",
    "print(f\"Response:{chr(10)}{response.response}{chr(10)}\")\n",
    "\n",
    "text_md = \"\"\n",
    "text_wd = \"\"\n",
    "\n",
    "for n in response.source_nodes:\n",
    "\n",
    "    window = n.node.metadata[\"window\"]\n",
    "    sentence = n.node.metadata[\"original_text\"]\n",
    "    \n",
    "    text_md += (\n",
    "        f\"**Node ID:** {n.node.node_id}{chr(10)}\"\n",
    "        f\"**Similarity:** {n.score}{chr(10)}\"\n",
    "        f\"**Text:** {n.node.get_content()}{chr(10)}\"\n",
    "        f\"{chr(10)}------------------{chr(10)}\"\n",
    "        f\"***Original Sentence***:{chr(10)} {sentence}\"\n",
    "        f\"{chr(10)}------------------{chr(10)}\"\n",
    "        f\"***Window***:{chr(10)}{window}{chr(10)}\"\n",
    "        f\"~~~~{chr(10)}\"\n",
    "    )\n",
    "      \n",
    "    \n",
    "print(text_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the evalution question set (along with expected answers)\n",
    "- This is structured in Llamaindex's format for batch evaluations\n",
    "- Also, load into a data frame (which we will write back to an excel file with responses, evaluations etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(eval_questions, 'r') as file:\n",
    "    data = pd.read_json(file)\n",
    "     \n",
    "    queries_df = pd.DataFrame(list(data['queries'].items()), columns=['query_num', 'query'])\n",
    "    responses_df = pd.DataFrame(list(data['responses'].items()), columns=['query_num', 'expected_answer'])\n",
    "    \n",
    "    responses_df = pd.merge(queries_df, responses_df, on='query_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation.eval_utils import (\n",
    "    get_responses,\n",
    ")\n",
    "from llama_index.core.evaluation import QueryResponseDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send questions to engine in bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shthanka.ORADEV\\AppData\\Local\\anaconda3\\Lib\\site-packages\\llama_index\\core\\evaluation\\dataset_generation.py:109: DeprecationWarning: Call to deprecated class QueryResponseDataset. (Deprecated in favor of `LabelledRagDataset` which should be used instead.)\n",
      "  return cls(**data)\n",
      "100%|██████████| 82/82 [00:42<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = QueryResponseDataset.from_json(eval_questions)\n",
    "eval_qs = eval_dataset.questions\n",
    "ref_response_strs = [r for (_, r) in eval_dataset.qr_pairs]\n",
    "pred_responses = get_responses(\n",
    "    eval_qs, query_engine, show_progress=True\n",
    ")\n",
    "pred_response_strs = [str(p) for p in pred_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple\n",
    "def get_answers_source_nodes(responses)->Tuple[list, list]:\n",
    "\n",
    "    answers = []\n",
    "    sources = []\n",
    "        \n",
    "    for response in responses:\n",
    "        answers.append(response.response)\n",
    "        text_md = \"\"\n",
    "        \n",
    "        for n in response.source_nodes:\n",
    "            window = n.node.metadata[\"window\"]\n",
    "            sentence = n.node.metadata[\"original_text\"]\n",
    "\n",
    "            text_md += (\n",
    "            f\"**Node ID:** {n.node.node_id}{chr(10)}\"\n",
    "            f\"**Similarity:** {n.score}{chr(10)}\"\n",
    "            f\"**Text:** {n.node.get_content()}{chr(10)}\"\n",
    "            f\"{chr(10)}------------------{chr(10)}\"\n",
    "            f\"***Original Sentence***:{chr(10)} {sentence}\"\n",
    "            f\"{chr(10)}------------------{chr(10)}\"\n",
    "            f\"***Window***:{chr(10)}{window}{chr(10)}\"\n",
    "            f\"~~~~{chr(10)}\"\n",
    "    )\n",
    "\n",
    "        sources.append(text_md)\n",
    "    \n",
    "    return answers, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers, sources = get_answers_source_nodes(pred_responses)\n",
    "\n",
    "responses_df['generated_answer'] = answers\n",
    "\n",
    "sources_df = pd.DataFrame()\n",
    "sources_df['query_num'] = responses_df['query_num']\n",
    "sources_df['query'] = responses_df['query']\n",
    "sources_df = sources_df.join(pd.DataFrame(sources)[0].str.split(\"~~~~\", expand=True))\n",
    "\n",
    "tokencount_df['answer_tokens' ] = [token_counter.total_llm_token_count]\n",
    "token_counter.reset_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output_file) as writer:\n",
    "   responses_df.to_excel(writer, sheet_name=\"Responses\", index=False)\n",
    "   sources_df.to_excel(writer, sheet_name=\"Sources\", index=False)\n",
    "   tokencount_df.to_excel(writer, sheet_name=\"Token Counts\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the LLM for evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_llm_family = os.environ[\"EVALUATION_LLM_FAMILY\"]\n",
    "evaluation_llm_model = os.environ[\"EVALUATION_LLM_MODEL\"]\n",
    "\n",
    "if evaluation_llm_family == \"OPENAI\":\n",
    "    Settings.eval_llm = OpenAI(temperature=0, model=evaluation_llm_model)\n",
    "elif evaluation_llm_family == \"COHERE\":\n",
    "    Settings.eval_llm = Cohere(api_key=os.environ[\"COHERE_API_KEY\"], model=evaluation_llm_model, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import QueryResponseDataset\n",
    "#import random\n",
    "\n",
    "from llama_index.core.evaluation.eval_utils import (\n",
    "    get_responses,\n",
    ")\n",
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "\n",
    "from llama_index.core.evaluation import (\n",
    "    CorrectnessEvaluator,\n",
    ")\n",
    "\n",
    "from deepeval.integrations.llama_index import (\n",
    "    DeepEvalAnswerRelevancyEvaluator,\n",
    "    DeepEvalFaithfulnessEvaluator,\n",
    "    DeepEvalContextualRelevancyEvaluator,\n",
    "    DeepEvalBiasEvaluator,\n",
    "    DeepEvalToxicityEvaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_lidx_c = CorrectnessEvaluator(llm=Settings.eval_llm)\n",
    "eval_deval_f = DeepEvalFaithfulnessEvaluator(threshold=0.5, model=evaluation_llm_model,include_reason=True)\n",
    "eval_deval_ar = DeepEvalAnswerRelevancyEvaluator( threshold=0.5, model=evaluation_llm_model,include_reason=True)\n",
    "eval_deval_cr = DeepEvalContextualRelevancyEvaluator(threshold=0.5, model=evaluation_llm_model,include_reason=True)\n",
    "eval_deval_b = DeepEvalBiasEvaluator(threshold=0.5, model=evaluation_llm_model,include_reason=True)\n",
    "eval_deval_t = DeepEvalToxicityEvaluator(threshold=0.5, model=evaluation_llm_model,include_reason=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For large eval sets (30+ questions)\n",
    "evaluator_dict_essential = {\n",
    "    \"Correctness\": eval_lidx_c,\n",
    "    \"Faithfulness\": eval_deval_f\n",
    "}\n",
    "\n",
    "# For troubleshooting \n",
    "evaluator_dict_extended = {\n",
    "    \"Correctness\": eval_lidx_c,\n",
    "    \"Faithfulness\": eval_deval_f,\n",
    "    \"Context_Relevancy\": eval_deval_cr\n",
    "}\n",
    "\n",
    "# For small sets (< 10 questions)\n",
    "evaluator_dict_full = {\n",
    "    \"Correctness\": eval_lidx_c,\n",
    "    \"Faithfulness\": eval_deval_f,\n",
    "    \"Answer_Relevancy\": eval_deval_ar,\n",
    "    \"Context_Relevancy\": eval_deval_cr,\n",
    "    \"Bias\": eval_deval_b,\n",
    "    \"Toxicity\": eval_deval_t ,\n",
    "}\n",
    "\n",
    "# Pick the list of evaluators to run\n",
    "evaluator_dict = evaluator_dict_essential\n",
    "\n",
    "# Make sure this list matches the chosenevaluator_dict \n",
    "evaluators = [\"Correctness\", \"Faithfulness\" ] \n",
    "\n",
    "batch_runner = BatchEvalRunner(evaluator_dict, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e47214f61ba4a49a6e63f7dac8fad06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd610fd2e2b46e99a821dabc9f27523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e326479dbc7a48fbb5ccb04886bae9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6204a650d0b44b184a96da71d010a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491ae58a96c74e75b682073935de44aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f87627a31249adac159ff944a1ce65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe00ba9d49e41f5bfdb3951bc005f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d096eb62ea46e792b2edfb2f6d4e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec2d104fee548a288378f3bbe219c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749091f3e73c4261abc0246ab4d1acf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1562e0ba1400412b8d83ba1040078391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206a3345b18943a6899f3972a1d73a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587fc6312bcf414f9c90cb0a4395e7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919daefb1071491588fa41392d12a7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4338a67db4433ea7ed98b702f80242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7905d68d3e424cde87f93ee73c8159b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0b755a1c22462e978c4c75b374afe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abb35033c1b41c28b3c5d0c709bad0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6129b70c0744e993e2a51b4479a460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b61d0a05cf44de683cd6d6b2ab21c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c96a26432f4ca0bd4f694274f28be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd62fae334b44859e351d618a8b7916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b9e6e6797448f8b9ee07584a7df340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bccef2af704808a33f9bb74126957f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e687241700f44371a89a41d162dabf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76452370ab04790aeaa1a766b2d415f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad6dade037444a1a72c509ffded5eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecff1ebccfd46df85ab3ab6ba28fb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6e512ca153418f9cc0616792bbe289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc06c837e8b4cf8a7c49e34e0b97b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef462340cc0e4935b16727ce531cd11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812d9c8e305a438cb09b951a08c818e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3d4974e1fd473f994e03f2ed3e90e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1a1ea0f63e45529013e26c9b240667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e267b841838436990d189ac75d2bc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9a3937cd044d6a80343ecf686c40b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1a9a67446942cdb0991d03f48fb9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99a4b7b48dd47469d1a62b57c53b056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e69b7d3e2c487abfb7d64e0c8e1810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f33f0f217884c5caee3a60e43cd1d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3930195b79f4b69b8e1b0fe2fd185ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726c95d21e524b81a09fb6ba6a61cfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7301c8d3fec24aa6b75cd587772dc1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61224f34fd543998c5e8f199a2ec627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ae4d5c4c9e4ee188b9334f33512323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c029b9ad53d54208a2a6bb28e65158f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ed1565d1954216836bfd312064f67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c44c8d442bf4a508057c429d455bdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b11519f84c4618954e013206f24318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7602e812b78b430ba60ee5673d9d6303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56e053e7dea4e948889a1dc4177971e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c5a537e4504e86839ad099596a1ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84f3e274afe4a3aae542d237d81834a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f57fae8cbfd4d88b460c6eea302ac55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a98db9bdbb41b881c57df431407db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d47452b16d41dd9471d448958e4aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9728f6633c4c91825a9cfb6fc900a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529b2b767f2f48649baff41d234977ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be28a375102424db31d22f7db7d1718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c5fad6c3dc4f9f86e5029468e54bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc99587d656405796bfea98c1225dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c899f15bea0f4a628d50478de6a7b0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3fd75d5281468288bd2310e5dd9c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2543ed866954741a9fe21ca353b78f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1edef17ef704858b6142d2daf3c87ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b9e402d0a742d3ab19825b052e2949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a24ce4e35054a32b52f46a5e015cec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e272ae4611410897b332f0652b2da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c280b93dd334071923e15db30945312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea54448935449ca8fef7cf178ede684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac918d7e86f04fa395cff686f8f48d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b93f02dff14621b4b58ad3cdc9f77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f63a89792c84f1d8758de7b74f10e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601a4ce89b9a441daafcb72c0048a83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5357cb999942b1bcf37d77080bfa4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526566d62cab454e9943e916a1632aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5c601e685640a997070bed4b421ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170b2b9ac0d848c3a134053beba18009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90cad836dff4162acb57287ea26e529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_results = await batch_runner.aevaluate_responses(\n",
    "    queries=eval_qs,\n",
    "    responses=pred_responses,\n",
    "    reference=ref_response_strs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_utils import get_eval_results_df, get_summary_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df, sum_df = get_summary_scores_df(\n",
    "    [eval_results ],\n",
    "    [rag_strategy],\n",
    "    evaluators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Correctness\" in evaluators:\n",
    "    correctness_df = get_eval_results_df(\n",
    "        list(responses_df['query_num']),\n",
    "        list(responses_df['expected_answer']),\n",
    "        eval_results[\"Correctness\"]\n",
    "    )\n",
    "    responses_df['correctness'] = correctness_df['score']\n",
    "\n",
    "if \"Faithfulness\" in evaluators:\n",
    "    faithfulness_df = get_eval_results_df(\n",
    "        list(responses_df['query_num']),\n",
    "        list(responses_df['expected_answer']),\n",
    "        eval_results[\"Faithfulness\"]\n",
    "    )\n",
    "    responses_df['faithfulness'] = faithfulness_df['score']\n",
    "\n",
    "if \"Answer_Relevancy\" in evaluators:\n",
    "    answer_relevancy_df = get_eval_results_df(\n",
    "        list(responses_df['query_num']),\n",
    "        list(responses_df['expected_answer']),\n",
    "        eval_results[\"Answer_Relevancy\"]\n",
    "    )\n",
    "    responses_df['answer_relevancy'] = answer_relevancy_df['score']\n",
    "\n",
    "if \"Context_Relevancy\" in evaluators:\n",
    "    context_relevancy_df = get_eval_results_df(\n",
    "        list(responses_df['query_num']),\n",
    "        list(responses_df['expected_answer']),\n",
    "        eval_results[\"Context_Relevancy\"]\n",
    "    )\n",
    "    responses_df['context_relevancy'] = context_relevancy_df['score']\n",
    "\n",
    "if \"Bias\" in evaluators:\n",
    "    bias_df = get_eval_results_df(\n",
    "        list(responses_df['query_num']),\n",
    "        list(responses_df['expected_answer']),\n",
    "        eval_results[\"Bias\"]\n",
    "    )\n",
    "    responses_df['bias'] = bias_df['score']\n",
    "\n",
    "if \"Toxicity\" in evaluators:\n",
    "    toxicity_df = get_eval_results_df(\n",
    "        list(responses_df['query_num']),\n",
    "        list(responses_df['expected_answer']),\n",
    "        eval_results[\"Toxicity\"]\n",
    "    )\n",
    "    responses_df['toxicity'] = toxicity_df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df['rag_strategy'] = rag_strategy\n",
    "responses_df['rag_strategy_desc'] = rag_strategy_desc\n",
    "responses_df['parameter_1'] = window_size\n",
    "responses_df['parameter_2'] = similarity_top_k\n",
    "if rag_strategy ==\"S002_00\":\n",
    "   responses_df['parameter_3'] = \"\"\n",
    "elif rag_strategy == \"S002_01\":\n",
    "    responses_df['parameter_3'] = rerank_top_n\n",
    "responses_df['parameter_4'] = \"\"\n",
    "responses_df['parameter_5'] = \"\"\n",
    "responses_df['model'] = generation_llm_model \n",
    "responses_df['embed_model'] = embedding_llm_model \n",
    "responses_df['eval_model'] = evaluation_llm_model\n",
    "responses_df['embed_dimensions'] = embedding_dimensions\n",
    "if rag_strategy ==\"S002_00\":\n",
    "   responses_df['reranker'] = \"\"\n",
    "elif rag_strategy == \"S002_01\":\n",
    "    responses_df['reranker'] = reranker\n",
    "responses_df['run_date'] = datetime.today().strftime('%Y-%m-%d') \n",
    "responses_df['eval_name'] = eval_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokencount_df['eval_tokens' ] = [token_counter.total_llm_token_count]\n",
    "token_counter.reset_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    responses_df.to_excel(writer, sheet_name=\"Responses\", index=False)\n",
    "    sources_df.to_excel(writer, sheet_name=\"Sources\", index=False)\n",
    "    \n",
    "    sum_df.to_excel(writer, sheet_name=\"Summary\", index=False, startrow=0 , startcol=0)\n",
    "    mean_df.to_excel(writer, sheet_name=\"Summary\", index=False,startrow=5, startcol=0)\n",
    "   \n",
    "  \n",
    "    if \"Correctness\" in evaluators:\n",
    "        correctness_df.to_excel(writer, sheet_name=\"Correctness\", index=False)\n",
    "    \n",
    "    if \"Faithfulness\" in evaluators:\n",
    "        faithfulness_df.to_excel(writer, sheet_name=\"Faithfulness\", index=False)\n",
    "\n",
    "    if \"Context_Relevancy\" in evaluators:\n",
    "        context_relevancy_df.to_excel(writer, sheet_name=\"Context_Relevancy\", index=False)\n",
    "    \n",
    "    if \"Answer_Relevancy\" in evaluators:\n",
    "        answer_relevancy_df.to_excel(writer, sheet_name=\"Answer_Relevancy\", index=False)\n",
    "\n",
    "    if \"Bias\" in evaluators:\n",
    "        bias_df.to_excel(writer, sheet_name=\"Bias\", index=False)\n",
    "\n",
    "    if \"Toxicity\" in evaluators:\n",
    "        toxicity_df.to_excel(writer, sheet_name=\"Toxicity\", index=False)\n",
    "    \n",
    "    tokencount_df.to_excel(writer, sheet_name=\"Token Counts\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
